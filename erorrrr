[osuser@bastion ~]$ oc logs recon-igjrdegwws-0-driver
WARNING: Using incubator modules: jdk.incubator.vector
Files local:///opt/spark/work-dir/recon-spark-job.jar from /opt/spark/work-dir/recon-spark-job.jar to /opt/spark/recon-spark-job.jar
25/09/24 09:53:33 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties
25/09/24 09:53:36 INFO SparkContext: Running Spark version 4.0.0
25/09/24 09:53:36 INFO SparkContext: OS info Linux, 5.14.0-427.44.1.el9_4.x86_64, amd64
25/09/24 09:53:36 INFO SparkContext: Java version 21.0.7
25/09/24 09:53:37 INFO ResourceUtils: ==============================================================
25/09/24 09:53:37 INFO ResourceUtils: No custom resources configured for spark.driver.
25/09/24 09:53:37 INFO ResourceUtils: ==============================================================
25/09/24 09:53:37 INFO SparkContext: Submitted application: operations-recon-spark-service
25/09/24 09:53:37 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 512, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/09/24 09:53:37 INFO ResourceProfile: Limiting resource is cpus at 1 tasks per executor
25/09/24 09:53:37 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/09/24 09:53:37 INFO SecurityManager: Changing view acls to: spark
25/09/24 09:53:37 INFO SecurityManager: Changing modify acls to: spark
25/09/24 09:53:37 INFO SecurityManager: Changing view acls groups to: spark
25/09/24 09:53:37 INFO SecurityManager: Changing modify acls groups to: spark
25/09/24 09:53:37 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY; RPC SSL disabled
25/09/24 09:53:37 INFO Utils: Successfully started service 'sparkDriver' on port 7078.
25/09/24 09:53:37 INFO SparkEnv: Registering MapOutputTracker
25/09/24 09:53:37 INFO SparkEnv: Registering BlockManagerMaster
25/09/24 09:53:37 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/09/24 09:53:37 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/09/24 09:53:37 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/09/24 09:53:37 INFO DiskBlockManager: Created local directory at /var/data/spark-f5ff3fb2-b209-432c-9971-cc16999dadbe/blockmgr-9d3e379c-10fc-48fd-b3e3-cfdf791788ba
25/09/24 09:53:37 INFO SparkEnv: Registering OutputCommitCoordinator
25/09/24 09:53:37 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
25/09/24 09:53:37 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/09/24 09:53:37 INFO SparkContext: Added JAR local:/opt/spark/work-dir/recon-spark-job.jar at file:/opt/spark/work-dir/recon-spark-job.jar with timestamp 1758707616963
25/09/24 09:53:37 INFO SecurityManager: Changing view acls to: spark
25/09/24 09:53:37 INFO SecurityManager: Changing modify acls to: spark
25/09/24 09:53:37 INFO SecurityManager: Changing view acls groups to: spark
25/09/24 09:53:37 INFO SecurityManager: Changing modify acls groups to: spark
25/09/24 09:53:37 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY; RPC SSL disabled
25/09/24 09:53:38 INFO SparkKubernetesClientFactory: Auto-configuring K8S client using current context from users K8S config file
25/09/24 09:53:39 INFO ExecutorPodsAllocator: Going to request 2 executors from Kubernetes for ResourceProfile Id: 0, target: 2, known: 0, sharedSlotFromPendingPods: 2147483647.
25/09/24 09:53:39 INFO ExecutorPodsAllocator: Found 0 reusable PVCs from 0 PVCs
25/09/24 09:53:39 INFO KubernetesClientUtils: Spark configuration files loaded from Some(/opt/spark/conf) : spark.kubernetes.namespace
25/09/24 09:53:39 INFO KubernetesClientUtils: Spark configuration files loaded from Some(/opt/spark/conf) : spark.kubernetes.namespace
25/09/24 09:53:39 INFO BasicExecutorFeatureStep: Decommissioning not enabled, skipping shutdown script
25/09/24 09:53:39 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 7079.
25/09/24 09:53:39 INFO NettyBlockTransferService: Server created on recon-igjrdegwws-0-driver-svc.dev-rns.svc 172.16.21.20:7079
25/09/24 09:53:39 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/09/24 09:53:39 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, recon-igjrdegwws-0-driver-svc.dev-rns.svc, 7079, None)
25/09/24 09:53:39 INFO BlockManagerMasterEndpoint: Registering block manager recon-igjrdegwws-0-driver-svc.dev-rns.svc:7079 with 1048.8 MiB RAM, BlockManagerId(driver, recon-igjrdegwws-0-driver-svc.dev-rns.svc, 7079, None)
25/09/24 09:53:39 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, recon-igjrdegwws-0-driver-svc.dev-rns.svc, 7079, None)
25/09/24 09:53:39 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, recon-igjrdegwws-0-driver-svc.dev-rns.svc, 7079, None)
25/09/24 09:53:39 INFO KubernetesClientUtils: Spark configuration files loaded from Some(/opt/spark/conf) : spark.kubernetes.namespace
25/09/24 09:53:39 INFO BasicExecutorFeatureStep: Decommissioning not enabled, skipping shutdown script
25/09/24 09:53:43 INFO KubernetesClusterSchedulerBackend$KubernetesDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.16.19.13:48678) with ID 2, ResourceProfileId 0
25/09/24 09:53:43 INFO BlockManagerMasterEndpoint: Registering block manager 172.16.19.13:41973 with 117.0 MiB RAM, BlockManagerId(2, 172.16.19.13, 41973, None)
25/09/24 09:53:43 INFO KubernetesClusterSchedulerBackend$KubernetesDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.16.22.5:32920) with ID 1, ResourceProfileId 0
25/09/24 09:53:43 INFO KubernetesClusterSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8
25/09/24 09:53:44 INFO BlockManagerMasterEndpoint: Registering block manager 172.16.22.5:34773 with 117.0 MiB RAM, BlockManagerId(1, 172.16.22.5, 34773, None)
25/09/24 09:53:45 INFO ReconSparkAppMain: Input properties: {spark.submit.pyFiles=, java.specification.version=21, sun.jnu.encoding=UTF-8, sun.arch.data.model=64, java.vendor.url=https://adoptium.net/, spark.kubernetes.submitInDriver=true, spark.kubernetes.authenticate.driver.serviceAccountName=spark-sa, sun.boot.library.path=/opt/java/openjdk/lib, sun.java.command=org.apache.spark.deploy.SparkSubmit --deploy-mode client --conf spark.driver.bindAddress=172.16.21.20 --conf spark.executorEnv.SPARK_DRIVER_POD_IP=172.16.21.20 --properties-file /opt/spark/conf/spark.properties --class com.epay.operations.recon.ReconSparkAppMain local:///opt/spark/work-dir/recon-spark-job.jar, jdk.debug=release, spark.kubernetes.executor.serviceAccount=spark-sa, io.netty.tryReflectionSetAccessible=true, java.specification.vendor=Oracle Corporation, spark.app.name=com.epay.operations.recon.ReconSparkAppMain, spark.executorEnv.SPARK_DRIVER_POD_IP=172.16.21.20, java.version.date=2025-04-15, java.home=/opt/java/openjdk, spark.kubernetes.executor.label.test=validation, spark.driver.blockManager.port=7079, file.separator=/, java.vm.compressedOopsMode=32-bit, line.separator=
, java.vm.specification.vendor=Oracle Corporation, java.specification.name=Java Platform API Specification, spark.kubernetes.memoryOverheadFactor=0.1, spark.kubernetes.driver.label.spark.operator/name=spark-kubernetes-operator, spark.kubernetes.driver.label.app=recon-spark-main, spark.jars=local:/opt/spark/work-dir/recon-spark-job.jar, spark.driver.port=7078, spark.kubernetes.driver.label.spark.operator/spark-app-name=recon-igjrdegwws, sun.management.compiler=HotSpot 64-Bit Tiered Compilers, java.runtime.version=21.0.7+6-LTS, user.name=spark, spark.driver.bindAddress=172.16.21.20, file.encoding=UTF-8, spark.kubernetes.driver.pod.name=recon-igjrdegwws-0-driver, rfId=1a6cf13c-df22-4845-a15a-f740e2716016, java.vendor.version=Temurin-21.0.7+6, spark.executor.instances=2, spark.executor.memory=512m, java.io.tmpdir=/tmp, java.version=21.0.7, java.vm.specification.name=Java Virtual Machine Specification, spark.submit.deployMode=client, native.encoding=UTF-8, java.library.path=/usr/java/packages/lib:/usr/lib64:/lib64:/lib:/usr/lib, spark.kubernetes.container.image=registry.dev.sbiepay.sbi:8443/spark/sparkrecon:4.0.0_12092025v13, stderr.encoding=UTF-8, java.vendor=Eclipse Adoptium, sun.io.unicode.encoding=UnicodeLittle, spark.kubernetes.driver.label.test=validation, java.class.path=hive-jackson/*:/opt/spark/conf/:/opt/spark/jars/slf4j-api-2.0.16.jar:/opt/spark/jars/HikariCP-2.5.1.jar:/opt/spark/jars/JLargeArrays-1.5.jar:/opt/spark/jars/JTransforms-3.1.jar:/opt/spark/jars/RoaringBitmap-1.3.0.jar:/opt/spark/jars/ST4-4.0.4.jar:/opt/spark/jars/aircompressor-2.0.2.jar:/opt/spark/jars/algebra_2.13-2.8.0.jar:/opt/spark/jars/annotations-17.0.0.jar:/opt/spark/jars/antlr-runtime-3.5.2.jar:/opt/spark/jars/antlr4-runtime-4.13.1.jar:/opt/spark/jars/aopalliance-repackaged-3.0.6.jar:/opt/spark/jars/arpack-3.0.3.jar:/opt/spark/jars/arpack_combined_all-0.1.jar:/opt/spark/jars/arrow-format-18.1.0.jar:/opt/spark/jars/arrow-memory-core-18.1.0.jar:/opt/spark/jars/arrow-memory-netty-18.1.0.jar:/opt/spark/jars/arrow-memory-netty-buffer-patch-18.1.0.jar:/opt/spark/jars/arrow-vector-18.1.0.jar:/opt/spark/jars/audience-annotations-0.12.0.jar:/opt/spark/jars/avro-1.12.0.jar:/opt/spark/jars/avro-ipc-1.12.0.jar:/opt/spark/jars/avro-mapred-1.12.0.jar:/opt/spark/jars/bcprov-jdk18on-1.80.jar:/opt/spark/jars/blas-3.0.3.jar:/opt/spark/jars/breeze-macros_2.13-2.1.0.jar:/opt/spark/jars/breeze_2.13-2.1.0.jar:/opt/spark/jars/cats-kernel_2.13-2.8.0.jar:/opt/spark/jars/checker-qual-3.43.0.jar:/opt/spark/jars/chill-java-0.10.0.jar:/opt/spark/jars/chill_2.13-0.10.0.jar:/opt/spark/jars/commons-cli-1.9.0.jar:/opt/spark/jars/commons-codec-1.17.2.jar:/opt/spark/jars/commons-collections-3.2.2.jar:/opt/spark/jars/commons-collections4-4.4.jar:/opt/spark/jars/commons-compiler-3.1.9.jar:/opt/spark/jars/commons-compress-1.27.1.jar:/opt/spark/jars/commons-crypto-1.1.0.jar:/opt/spark/jars/commons-dbcp-1.4.jar:/opt/spark/jars/commons-io-2.18.0.jar:/opt/spark/jars/commons-lang-2.6.jar:/opt/spark/jars/commons-lang3-3.17.0.jar:/opt/spark/jars/commons-math3-3.6.1.jar:/opt/spark/jars/commons-pool-1.5.4.jar:/opt/spark/jars/commons-text-1.13.0.jar:/opt/spark/jars/compress-lzf-1.1.2.jar:/opt/spark/jars/curator-client-5.7.1.jar:/opt/spark/jars/curator-framework-5.7.1.jar:/opt/spark/jars/curator-recipes-5.7.1.jar:/opt/spark/jars/datanucleus-api-jdo-4.2.4.jar:/opt/spark/jars/datanucleus-core-4.1.17.jar:/opt/spark/jars/datanucleus-rdbms-4.1.19.jar:/opt/spark/jars/datasketches-java-6.1.1.jar:/opt/spark/jars/datasketches-memory-3.0.2.jar:/opt/spark/jars/derby-10.16.1.1.jar:/opt/spark/jars/derbyshared-10.16.1.1.jar:/opt/spark/jars/derbytools-10.16.1.1.jar:/opt/spark/jars/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar:/opt/spark/jars/error_prone_annotations-2.36.0.jar:/opt/spark/jars/failureaccess-1.0.2.jar:/opt/spark/jars/flatbuffers-java-24.3.25.jar:/opt/spark/jars/gson-2.11.0.jar:/opt/spark/jars/guava-33.4.0-jre.jar:/opt/spark/jars/hadoop-client-api-3.4.1.jar:/opt/spark/jars/hadoop-client-runtime-3.4.1.jar:/opt/spark/jars/hive-beeline-2.3.10.jar:/opt/spark/jars/hive-cli-2.3.10.jar:/opt/spark/jars/hive-common-2.3.10.jar:/opt/spark/jars/hive-exec-2.3.10-core.jar:/opt/spark/jars/hive-jdbc-2.3.10.jar:/opt/spark/jars/hive-metastore-2.3.10.jar:/opt/spark/jars/hive-serde-2.3.10.jar:/opt/spark/jars/hive-service-rpc-4.0.0.jar:/opt/spark/jars/hive-shims-0.23-2.3.10.jar:/opt/spark/jars/hive-shims-2.3.10.jar:/opt/spark/jars/hive-shims-common-2.3.10.jar:/opt/spark/jars/hive-shims-scheduler-2.3.10.jar:/opt/spark/jars/hive-storage-api-2.8.1.jar:/opt/spark/jars/hk2-api-3.0.6.jar:/opt/spark/jars/hk2-locator-3.0.6.jar:/opt/spark/jars/hk2-utils-3.0.6.jar:/opt/spark/jars/httpclient-4.5.14.jar:/opt/spark/jars/httpcore-4.4.16.jar:/opt/spark/jars/icu4j-76.1.jar:/opt/spark/jars/istack-commons-runtime-4.1.2.jar:/opt/spark/jars/ivy-2.5.3.jar:/opt/spark/jars/j2objc-annotations-3.0.0.jar:/opt/spark/jars/jackson-annotations-2.18.2.jar:/opt/spark/jars/jackson-core-2.18.2.jar:/opt/spark/jars/jackson-databind-2.18.2.jar:/opt/spark/jars/jackson-dataformat-yaml-2.18.2.jar:/opt/spark/jars/jackson-datatype-jsr310-2.18.2.jar:/opt/spark/jars/jackson-module-scala_2.13-2.18.2.jar:/opt/spark/jars/jakarta.activation-api-2.1.3.jar:/opt/spark/jars/jakarta.annotation-api-2.1.1.jar:/opt/spark/jars/jakarta.inject-api-2.0.1.jar:/opt/spark/jars/jakarta.servlet-api-5.0.0.jar:/opt/spark/jars/jakarta.validation-api-3.0.2.jar:/opt/spark/jars/jakarta.ws.rs-api-3.0.0.jar:/opt/spark/jars/jpam-1.1.jar:/opt/spark/jars/jakarta.xml.bind-api-4.0.2.jar:/opt/spark/jars/janino-3.1.9.jar:/opt/spark/jars/java-diff-utils-4.15.jar:/opt/spark/jars/javassist-3.30.2-GA.jar:/opt/spark/jars/javax.jdo-3.2.0-m3.jar:/opt/spark/jars/javax.servlet-api-4.0.1.jar:/opt/spark/jars/javolution-5.5.1.jar:/opt/spark/jars/jaxb-core-4.0.5.jar:/opt/spark/jars/jaxb-runtime-4.0.5.jar:/opt/spark/jars/jcl-over-slf4j-2.0.16.jar:/opt/spark/jars/jdo-api-3.0.1.jar:/opt/spark/jars/jersey-client-3.0.16.jar:/opt/spark/jars/jersey-common-3.0.16.jar:/opt/spark/jars/jersey-container-servlet-3.0.16.jar:/opt/spark/jars/jersey-container-servlet-core-3.0.16.jar:/opt/spark/jars/jersey-hk2-3.0.16.jar:/opt/spark/jars/jersey-server-3.0.16.jar:/opt/spark/jars/jjwt-api-0.12.6.jar:/opt/spark/jars/jjwt-impl-0.12.6.jar:/opt/spark/jars/jjwt-jackson-0.12.6.jar:/opt/spark/jars/jline-2.14.6.jar:/opt/spark/jars/jline-3.27.1-jdk8.jar:/opt/spark/jars/joda-time-2.13.0.jar:/opt/spark/jars/jodd-core-3.5.2.jar:/opt/spark/jars/json-1.8.jar:/opt/spark/jars/json4s-ast_2.13-4.0.7.jar:/opt/spark/jars/json4s-core_2.13-4.0.7.jar:/opt/spark/jars/json4s-jackson-core_2.13-4.0.7.jar:/opt/spark/jars/json4s-jackson_2.13-4.0.7.jar:/opt/spark/jars/json4s-scalap_2.13-4.0.7.jar:/opt/spark/jars/jsr305-3.0.0.jar:/opt/spark/jars/jta-1.1.jar:/opt/spark/jars/jul-to-slf4j-2.0.16.jar:/opt/spark/jars/kryo-shaded-4.0.3.jar:/opt/spark/jars/kubernetes-client-7.1.0.jar:/opt/spark/jars/kubernetes-client-api-7.1.0.jar:/opt/spark/jars/kubernetes-httpclient-vertx-7.1.0.jar:/opt/spark/jars/kubernetes-model-admissionregistration-7.1.0.jar:/opt/spark/jars/kubernetes-model-apiextensions-7.1.0.jar:/opt/spark/jars/kubernetes-model-apps-7.1.0.jar:/opt/spark/jars/kubernetes-model-autoscaling-7.1.0.jar:/opt/spark/jars/kubernetes-model-batch-7.1.0.jar:/opt/spark/jars/kubernetes-model-certificates-7.1.0.jar:/opt/spark/jars/kubernetes-model-common-7.1.0.jar:/opt/spark/jars/kubernetes-model-coordination-7.1.0.jar:/opt/spark/jars/kubernetes-model-core-7.1.0.jar:/opt/spark/jars/kubernetes-model-discovery-7.1.0.jar:/opt/spark/jars/kubernetes-model-events-7.1.0.jar:/opt/spark/jars/kubernetes-model-extensions-7.1.0.jar:/opt/spark/jars/kubernetes-model-flowcontrol-7.1.0.jar:/opt/spark/jars/kubernetes-model-gatewayapi-7.1.0.jar:/opt/spark/jars/kubernetes-model-metrics-7.1.0.jar:/opt/spark/jars/kubernetes-model-networking-7.1.0.jar:/opt/spark/jars/kubernetes-model-node-7.1.0.jar:/opt/spark/jars/kubernetes-model-policy-7.1.0.jar:/opt/spark/jars/kubernetes-model-rbac-7.1.0.jar:/opt/spark/jars/kubernetes-model-resource-7.1.0.jar:/opt/spark/jars/kubernetes-model-scheduling-7.1.0.jar:/opt/spark/jars/kubernetes-model-storageclass-7.1.0.jar:/opt/spark/jars/lapack-3.0.3.jar:/opt/spark/jars/leveldbjni-all-1.8.jar:/opt/spark/jars/libfb303-0.9.3.jar:/opt/spark/jars/libthrift-0.16.0.jar:/opt/spark/jars/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/spark/jars/log4j-1.2-api-2.24.3.jar:/opt/spark/jars/log4j-api-2.24.3.jar:/opt/spark/jars/log4j-core-2.24.3.jar:/opt/spark/jars/log4j-layout-template-json-2.24.3.jar:/opt/spark/jars/log4j-slf4j2-impl-2.24.3.jar:/opt/spark/jars/lz4-java-1.8.0.jar:/opt/spark/jars/metrics-core-4.2.30.jar:/opt/spark/jars/metrics-graphite-4.2.30.jar:/opt/spark/jars/metrics-jmx-4.2.30.jar:/opt/spark/jars/metrics-json-4.2.30.jar:/opt/spark/jars/metrics-jvm-4.2.30.jar:/opt/spark/jars/minlog-1.3.0.jar:/opt/spark/jars/netty-all-4.1.118.Final.jar:/opt/spark/jars/netty-buffer-4.1.118.Final.jar:/opt/spark/jars/netty-codec-4.1.118.Final.jar:/opt/spark/jars/netty-codec-dns-4.1.118.Final.jar:/opt/spark/jars/netty-codec-http-4.1.118.Final.jar:/opt/spark/jars/netty-codec-http2-4.1.118.Final.jar:/opt/spark/jars/netty-codec-socks-4.1.118.Final.jar:/opt/spark/jars/netty-common-4.1.118.Final.jar:/opt/spark/jars/netty-handler-4.1.118.Final.jar:/opt/spark/jars/netty-handler-proxy-4.1.118.Final.jar:/opt/spark/jars/netty-resolver-4.1.118.Final.jar:/opt/spark/jars/netty-resolver-dns-4.1.118.Final.jar:/opt/spark/jars/netty-tcnative-boringssl-static-2.0.70.Final-linux-aarch_64.jar:/opt/spark/jars/netty-tcnative-boringssl-static-2.0.70.Final-linux-x86_64.jar:/opt/spark/jars/netty-tcnative-boringssl-static-2.0.70.Final-osx-aarch_64.jar:/opt/spark/jars/netty-tcnative-boringssl-static-2.0.70.Final-osx-x86_64.jar:/opt/spark/jars/netty-tcnative-boringssl-static-2.0.70.Final-windows-x86_64.jar:/opt/spark/jars/netty-tcnative-classes-2.0.70.Final.jar:/opt/spark/jars/netty-transport-4.1.118.Final.jar:/opt/spark/jars/netty-transport-classes-epoll-4.1.118.Final.jar:/opt/spark/jars/netty-transport-classes-kqueue-4.1.118.Final.jar:/opt/spark/jars/netty-transport-native-epoll-4.1.118.Final-linux-aarch_64.jar:/opt/spark/jars/netty-transport-native-epoll-4.1.118.Final-linux-riscv64.jar:/opt/spark/jars/netty-transport-native-epoll-4.1.118.Final-linux-x86_64.jar:/opt/spark/jars/netty-transport-native-kqueue-4.1.118.Final-osx-aarch_64.jar:/opt/spark/jars/netty-transport-native-kqueue-4.1.118.Final-osx-x86_64.jar:/opt/spark/jars/netty-transport-native-unix-common-4.1.118.Final.jar:/opt/spark/jars/objenesis-3.3.jar:/opt/spark/jars/opencsv-2.3.jar:/opt/spark/jars/orc-core-2.1.2-shaded-protobuf.jar:/opt/spark/jars/orc-format-1.1.0-shaded-protobuf.jar:/opt/spark/jars/orc-mapreduce-2.1.2-shaded-protobuf.jar:/opt/spark/jars/orc-shims-2.1.2.jar:/opt/spark/jars/oro-2.0.8.jar:/opt/spark/jars/osgi-resource-locator-1.0.3.jar:/opt/spark/jars/paranamer-2.8.jar:/opt/spark/jars/parquet-column-1.15.2.jar:/opt/spark/jars/parquet-common-1.15.2.jar:/opt/spark/jars/parquet-encoding-1.15.2.jar:/opt/spark/jars/parquet-format-structures-1.15.2.jar:/opt/spark/jars/parquet-hadoop-1.15.2.jar:/opt/spark/jars/parquet-jackson-1.15.2.jar:/opt/spark/jars/pickle-1.5.jar:/opt/spark/jars/py4j-0.10.9.9.jar:/opt/spark/jars/rocksdbjni-9.8.4.jar:/opt/spark/jars/scala-collection-compat_2.13-2.7.0.jar:/opt/spark/jars/scala-compiler-2.13.16.jar:/opt/spark/jars/scala-library-2.13.16.jar:/opt/spark/jars/scala-parallel-collections_2.13-1.2.0.jar:/opt/spark/jars/scala-parser-combinators_2.13-2.4.0.jar:/opt/spark/jars/scala-reflect-2.13.16.jar:/opt/spark/jars/scala-xml_2.13-2.3.0.jar:/opt/spark/jars/slf4j-api-2.0.16.jar:/opt/spark/jars/snakeyaml-2.3.jar:/opt/spark/jars/snakeyaml-engine-2.9.jar:/opt/spark/jars/snappy-java-1.1.10.7.jar:/opt/spark/jars/spark-catalyst_2.13-4.0.0.jar:/opt/spark/jars/spark-common-utils_2.13-4.0.0.jar:/opt/spark/jars/spark-connect_2.13-4.0.0.jar:/opt/spark/jars/spark-core_2.13-4.0.0.jar:/opt/spark/jars/spark-graphx_2.13-4.0.0.jar:/opt/spark/jars/spark-hive-thriftserver_2.13-4.0.0.jar:/opt/spark/jars/spark-hive_2.13-4.0.0.jar:/opt/spark/jars/spark-kubernetes_2.13-4.0.0.jar:/opt/spark/jars/spark-kvstore_2.13-4.0.0.jar:/opt/spark/jars/spark-launcher_2.13-4.0.0.jar:/opt/spark/jars/spark-mllib-local_2.13-4.0.0.jar:/opt/spark/jars/spark-mllib_2.13-4.0.0.jar:/opt/spark/jars/spark-network-common_2.13-4.0.0.jar:/opt/spark/jars/spark-network-shuffle_2.13-4.0.0.jar:/opt/spark/jars/spark-repl_2.13-4.0.0.jar:/opt/spark/jars/spark-sketch_2.13-4.0.0.jar:/opt/spark/jars/spark-sql-api_2.13-4.0.0.jar:/opt/spark/jars/spark-sql_2.13-4.0.0.jar:/opt/spark/jars/spark-streaming_2.13-4.0.0.jar:/opt/spark/jars/spark-tags_2.13-4.0.0.jar:/opt/spark/jars/spark-unsafe_2.13-4.0.0.jar:/opt/spark/jars/spark-variant_2.13-4.0.0.jar:/opt/spark/jars/spark-yarn_2.13-4.0.0.jar:/opt/spark/jars/spire-macros_2.13-0.18.0.jar:/opt/spark/jars/spire-platform_2.13-0.18.0.jar:/opt/spark/jars/spire-util_2.13-0.18.0.jar:/opt/spark/jars/spire_2.13-0.18.0.jar:/opt/spark/jars/stax-api-1.0.1.jar:/opt/spark/jars/stream-2.9.8.jar:/opt/spark/jars/super-csv-2.2.0.jar:/opt/spark/jars/threeten-extra-1.8.0.jar:/opt/spark/jars/tink-1.16.0.jar:/opt/spark/jars/transaction-api-1.1.jar:/opt/spark/jars/univocity-parsers-2.9.1.jar:/opt/spark/jars/vertx-auth-common-4.5.12.jar:/opt/spark/jars/vertx-core-4.5.12.jar:/opt/spark/jars/vertx-web-client-4.5.12.jar:/opt/spark/jars/vertx-web-common-4.5.12.jar:/opt/spark/jars/xbean-asm9-shaded-4.26.jar:/opt/spark/jars/xmlschema-core-2.3.1.jar:/opt/spark/jars/xz-1.10.jar:/opt/spark/jars/zjsonpatch-7.1.0.jar:/opt/spark/jars/zookeeper-3.9.3.jar:/opt/spark/jars/zookeeper-jute-3.9.3.jar:/opt/spark/jars/zstd-jni-1.5.6-9.jar, java.vm.vendor=Eclipse Adoptium, user.timezone=Etc/UTC, spark.sql.adaptive.enabled=true, os.name=Linux, java.vm.specification.version=21, sun.java.launcher=SUN_STANDARD, user.country=US, spark.driver.memory=2g, spark.master=k8s://https://$KUBERNETES_SERVICE_HOST:$KUBERNETES_SERVICE_PORT, spark.driver.cores=1, SPARK_SUBMIT=true, sun.cpu.endian=little, user.home=/nonexistent, user.language=en, derby.connection.requireAuthentication=false, spark.driver.host=recon-igjrdegwws-0-driver-svc.dev-rns.svc, spark.app.id=recon-igjrdegwws-0, spark.driver.extraJavaOptions=-DrfId=1a6cf13c-df22-4845-a15a-f740e2716016, spark.kubernetes.driver.service.label.spark.operator/name=spark-kubernetes-operator, spark.kubernetes.driver.service.label.spark.operator/spark-app-name=recon-igjrdegwws, spark.kubernetes.executor.label.app=recon-spark-main, spark.kubernetes.container.image.pullPolicy=Always, kubernetes.request.retry.backoffLimit=3, spark.kubernetes.resource.type=java, stdout.encoding=UTF-8, path.separator=:, os.version=5.14.0-427.44.1.el9_4.x86_64, java.runtime.name=OpenJDK Runtime Environment, spark.kubernetes.namespace=dev-rns, spark.app.submitTime=1758707613303, spark.kubernetes.executor.label.spark.operator/spark-app-name=recon-igjrdegwws, spark.sql.adaptive.coalescePartitions.enabled=true, java.vm.name=OpenJDK 64-Bit Server VM, java.vendor.url.bug=https://github.com/adoptium/adoptium-support/issues, jetty.git.hash=5dfc59a691b748796f922208956bd1f2794bcd16, user.dir=/opt/spark, spark.repl.local.jars=local:///opt/spark/work-dir/recon-spark-job.jar, os.arch=amd64, spark.executor.cores=1, spark.kubernetes.executor.label.spark.operator/name=spark-kubernetes-operator, java.vm.info=mixed mode, sharing, java.vm.version=21.0.7+6-LTS, spark.eventLog.enabled=false, jdk.reflect.useDirectMethodHandle=false, java.class.version=65.0}
25/09/24 09:53:45 INFO ReconSparkAppMain: Get env properties : null
25/09/24 09:53:45 INFO ReconSparkAppMain: Application Context Created!!!
25/09/24 09:53:45 INFO SparkReconProcessingService: Step-1: Fetch recon file details by rfId : 1a6cf13c-df22-4845-a15a-f740e2716015
25/09/24 09:53:45 INFO SparkReconProcessingService: Fetching recon file data by rfId : 1a6cf13c-df22-4845-a15a-f740e2716015
25/09/24 09:53:45 INFO ReconFileRepository: Getting recon file for rfId: 1a6cf13c-df22-4845-a15a-f740e2716015
25/09/24 09:53:46 INFO SparkReconProcessingService: Step-2: Fetch Bank config.
25/09/24 09:53:46 INFO AdminServiceClient: Fetching bank config from admin service:
25/09/24 09:53:46 INFO AdminServiceClient: Uri : [http://admin-adminservice.dev-admin.svc.cluster.local:9094/api/admin/v1/rns/3c1450ab-f57d-525f-e063-7c86b10acd50]
25/09/24 09:53:47 WARN HttpClientConnect: [5ec4f6bc-1, L:/172.16.21.20:33588 ! R:admin-adminservice.dev-admin.svc.cluster.local/172.30.141.6:9094] The connection observed an error
reactor.netty.http.client.PrematureCloseException: Connection prematurely closed BEFORE response
org.springframework.web.reactive.function.client.WebClientRequestException: Connection prematurely closed BEFORE response
        at org.springframework.web.reactive.function.client.ExchangeFunctions$DefaultExchangeFunction.lambda$wrapException$9(ExchangeFunctions.java:136)
        Suppressed: The stacktrace has been enhanced by Reactor, refer to additional information below:
Error has been observed at the following site(s):
        *__checkpoint â‡¢ Request to POST http://admin-adminservice.dev-admin.svc.cluster.local:9094/api/admin/v1/rns/3c1450ab-f57d-525f-e063-7c86b10acd50 [DefaultWebClient]
Original Stack Trace:
                at org.springframework.web.reactive.function.client.ExchangeFunctions$DefaultExchangeFunction.lambda$wrapException$9(ExchangeFunctions.java:136)
                at reactor.core.publisher.MonoErrorSupplied.subscribe(MonoErrorSupplied.java:55)
                at reactor.core.publisher.Mono.subscribe(Mono.java:4576)
                at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onError(FluxOnErrorResume.java:103)
                at reactor.core.publisher.FluxPeek$PeekSubscriber.onError(FluxPeek.java:222)
                at reactor.core.publisher.FluxPeek$PeekSubscriber.onError(FluxPeek.java:222)
                at reactor.core.publisher.FluxPeek$PeekSubscriber.onError(FluxPeek.java:222)
                at reactor.core.publisher.MonoNext$NextSubscriber.onError(MonoNext.java:93)
                at reactor.core.publisher.MonoFlatMapMany$FlatMapManyMain.onError(MonoFlatMapMany.java:205)
                at reactor.core.publisher.SerializedSubscriber.onError(SerializedSubscriber.java:124)
                at reactor.core.publisher.FluxRetryWhen$RetryWhenMainSubscriber.whenError(FluxRetryWhen.java:229)
                at reactor.core.publisher.FluxRetryWhen$RetryWhenOtherSubscriber.onError(FluxRetryWhen.java:279)
                at reactor.core.publisher.FluxContextWrite$ContextWriteSubscriber.onError(FluxContextWrite.java:121)
                at reactor.core.publisher.FluxConcatMapNoPrefetch$FluxConcatMapNoPrefetchSubscriber.maybeOnError(FluxConcatMapNoPrefetch.java:327)
                at reactor.core.publisher.FluxConcatMapNoPrefetch$FluxConcatMapNoPrefetchSubscriber.onNext(FluxConcatMapNoPrefetch.java:212)
                at reactor.core.publisher.FluxContextWrite$ContextWriteSubscriber.onNext(FluxContextWrite.java:107)
                at reactor.core.publisher.SinkManyEmitterProcessor.drain(SinkManyEmitterProcessor.java:476)
                at reactor.core.publisher.SinkManyEmitterProcessor$EmitterInner.drainParent(SinkManyEmitterProcessor.java:620)
                at reactor.core.publisher.FluxPublish$PubSubInner.request(FluxPublish.java:874)
                at reactor.core.publisher.FluxContextWrite$ContextWriteSubscriber.request(FluxContextWrite.java:136)
                at reactor.core.publisher.FluxConcatMapNoPrefetch$FluxConcatMapNoPrefetchSubscriber.request(FluxConcatMapNoPrefetch.java:337)
                at reactor.core.publisher.FluxContextWrite$ContextWriteSubscriber.request(FluxContextWrite.java:136)
                at reactor.core.publisher.Operators$DeferredSubscription.request(Operators.java:1742)
                at reactor.core.publisher.FluxRetryWhen$RetryWhenMainSubscriber.onError(FluxRetryWhen.java:196)
                at reactor.core.publisher.MonoCreate$DefaultMonoSink.error(MonoCreate.java:205)
                at reactor.netty.http.client.HttpClientConnect$HttpObserver.onUncaughtException(HttpClientConnect.java:417)
                at reactor.netty.ReactorNetty$CompositeConnectionObserver.onUncaughtException(ReactorNetty.java:715)
                at reactor.netty.resources.DefaultPooledConnectionProvider$DisposableAcquire.onUncaughtException(DefaultPooledConnectionProvider.java:225)
                at reactor.netty.resources.DefaultPooledConnectionProvider$PooledConnection.onUncaughtException(DefaultPooledConnectionProvider.java:478)
                at reactor.netty.http.client.HttpClientOperations.onInboundClose(HttpClientOperations.java:352)
                at reactor.netty.channel.ChannelOperationsHandler.channelInactive(ChannelOperationsHandler.java:73)
                at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:303)
                at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:281)
                at io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:274)
                at io.netty.channel.CombinedChannelDuplexHandler$DelegatingChannelHandlerContext.fireChannelInactive(CombinedChannelDuplexHandler.java:418)
                at io.netty.handler.codec.ByteToMessageDecoder.channelInputClosed(ByteToMessageDecoder.java:412)
                at io.netty.handler.codec.ByteToMessageDecoder.channelInactive(ByteToMessageDecoder.java:377)
                at io.netty.handler.codec.http.HttpClientCodec$Decoder.channelInactive(HttpClientCodec.java:410)
                at io.netty.channel.CombinedChannelDuplexHandler.channelInactive(CombinedChannelDuplexHandler.java:221)
                at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:303)
                at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:281)
                at io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:274)
                at io.netty.channel.DefaultChannelPipeline$HeadContext.channelInactive(DefaultChannelPipeline.java:1352)
                at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:301)
                at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:281)
                at io.netty.channel.DefaultChannelPipeline.fireChannelInactive(DefaultChannelPipeline.java:850)
                at io.netty.channel.AbstractChannel$AbstractUnsafe$7.run(AbstractChannel.java:811)
                at io.netty.util.concurrent.AbstractEventExecutor.runTask(AbstractEventExecutor.java:173)
                at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:166)
                at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:472)
                at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:405)
                at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:998)
                at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
                at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
                at java.base/java.lang.Thread.run(Thread.java:1583)
        Suppressed: java.lang.Exception: #block terminated with an error
                at reactor.core.publisher.BlockingSingleSubscriber.blockingGet(BlockingSingleSubscriber.java:104)
                at reactor.core.publisher.Mono.block(Mono.java:1779)
                at com.epay.operations.recon.spark.externalservice.AdminServiceClient.findFileConfigById(AdminServiceClient.java:45)
                at com.epay.operations.recon.spark.service.SparkReconProcessingService.reconProcessing(SparkReconProcessingService.java:60)
                at com.epay.operations.recon.ReconSparkAppMain.main(ReconSparkAppMain.java:69)
                at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
                at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
                at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
                at java.base/java.lang.reflect.Method.invoke(Method.java:580)
                at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)
                at org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:1027)
                at org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:204)
                at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:227)
                at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:96)
                at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1132)
                at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1141)
                at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
Caused by: reactor.netty.http.client.PrematureCloseException: Connection prematurely closed BEFORE response
25/09/24 09:53:47 ERROR ReconSparkAppMain: Exception while the recon process for rfId[1a6cf13c-df22-4845-a15a-f740e2716015], error message: Connection prematurely closed BEFORE response
25/09/24 09:53:47 INFO ReconSparkAppMain: Calling callback OPS API: http://ops-operationsservice.dev-spark.svc.cluster.local:9097/api/rns/v1/spark/recon-complete-callback
25/09/24 09:53:47 INFO ReconSparkAppMain: payload: {"rfId":"1a6cf13c-df22-4845-a15a-f740e2716015","jobId":"d7ae14c3-ceee-4936-90a5-9a865a0393f7","status":"FAILED","message":"Failed recon spark job, error message: Connection prematurely closed BEFORE response"}
25/09/24 09:53:47 ERROR ReconSparkAppMain: IOException while calling the callback endpoint, error message: HTTP/1.1 header parser received no bytes
25/09/24 09:53:47 INFO SparkContext: SparkContext is stopping with exitCode 0 from stop at SparkSubmit.scala:1036.
25/09/24 09:53:47 INFO SparkUI: Stopped Spark web UI at http://recon-igjrdegwws-0-driver-svc.dev-rns.svc:4040
25/09/24 09:53:47 INFO KubernetesClusterSchedulerBackend: Shutting down all executors
25/09/24 09:53:47 INFO KubernetesClusterSchedulerBackend$KubernetesDriverEndpoint: Asking each executor to shut down
25/09/24 09:53:47 INFO ExecutorPodsWatchSnapshotSource: Kubernetes client has been closed.
25/09/24 09:53:47 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/09/24 09:53:47 INFO MemoryStore: MemoryStore started with capacity 1048.8 MiB
25/09/24 09:53:47 INFO MemoryStore: MemoryStore cleared
25/09/24 09:53:47 INFO BlockManager: BlockManager stopped
25/09/24 09:53:47 INFO BlockManagerMaster: BlockManagerMaster stopped
25/09/24 09:53:47 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/09/24 09:53:47 INFO SparkContext: Successfully stopped SparkContext
25/09/24 09:53:48 INFO ShutdownHookManager: Shutdown hook called
25/09/24 09:53:48 INFO ShutdownHookManager: Deleting directory /tmp/spark-a2e3ad6f-8029-41c3-889a-f73b6ca98902
25/09/24 09:53:48 INFO ShutdownHookManager: Deleting directory /var/data/spark-f5ff3fb2-b209-432c-9971-cc16999dadbe/spark-f969388e-7531-452f-9add-0a18ff58aa13
[osuser@bastion ~]$ ^C
[osuser@bastion ~]$
